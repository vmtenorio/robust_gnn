{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from opt import graph_id, graph_id_rew\n",
    "\n",
    "from arch import arch\n",
    "from arch import model\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "k = 4\n",
    "p = 0.4\n",
    "q = 0.05\n",
    "\n",
    "M = 1#50\n",
    "p_n = 0.1\n",
    "eps = 0.15\n",
    "L = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.SBMComLabel(N, k, p, q, M, L, data=\"diffused_sparse\", n_deltas=k)\n",
    "dataset.pert_S()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f69981cf790>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1,2,figsize=(12,6))\n",
    "ax[0].imshow(dataset.S)\n",
    "ax[1].imshow(dataset.Sn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "wd = 0\n",
    "n_epochs = 50\n",
    "n_layers = 3\n",
    "hid_dim = 128\n",
    "eval_freq = 100\n",
    "\n",
    "n_iters = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd, gamma, delta, inc_gamma = [5e-4, 1e-4, 10., 1.]\n",
    "gamma = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = int(0.7*N)\n",
    "dataset.create_mask(N_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_gcn = torch.Tensor(dataset.Sn).to(device)\n",
    "\n",
    "in_dim = 1\n",
    "out_dim = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 1]), torch.Size([50]), torch.float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.Tensor(dataset.x[:,None]).to(device)\n",
    "Y = torch.LongTensor(dataset.y).to(device)\n",
    "X.shape, Y.shape, X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500 - Loss: 4647.78759765625 - Train Acc: 0.2571428716182709 - Test Acc: 0.40000003576278687\n",
      "Epoch 100/1500 - Loss: 133.038330078125 - Train Acc: 0.2571428716182709 - Test Acc: 0.40000003576278687\n",
      "Epoch 200/1500 - Loss: 39.36719512939453 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n",
      "Epoch 300/1500 - Loss: 10.710365295410156 - Train Acc: 0.22857142984867096 - Test Acc: 0.20000001788139343\n",
      "Epoch 400/1500 - Loss: 4.13880729675293 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n",
      "Epoch 500/1500 - Loss: 1.3535692691802979 - Train Acc: 0.3142857253551483 - Test Acc: 0.2666666805744171\n",
      "Epoch 600/1500 - Loss: 1.0915980339050293 - Train Acc: 0.4285714328289032 - Test Acc: 0.5333333611488342\n",
      "Epoch 700/1500 - Loss: 1.0521305799484253 - Train Acc: 0.4285714328289032 - Test Acc: 0.6000000238418579\n",
      "Epoch 800/1500 - Loss: 1.0249780416488647 - Train Acc: 0.4285714328289032 - Test Acc: 0.6000000238418579\n",
      "Epoch 900/1500 - Loss: 1.0090876817703247 - Train Acc: 0.4285714328289032 - Test Acc: 0.6666666865348816\n",
      "Epoch 1000/1500 - Loss: 1.3979331254959106 - Train Acc: 0.2571428716182709 - Test Acc: 0.20000001788139343\n",
      "Epoch 1100/1500 - Loss: 0.9668473601341248 - Train Acc: 0.6571428775787354 - Test Acc: 0.5333333611488342\n",
      "Epoch 1200/1500 - Loss: 0.725074052810669 - Train Acc: 0.7428571581840515 - Test Acc: 0.7333333492279053\n",
      "Epoch 1300/1500 - Loss: 0.480073481798172 - Train Acc: 0.8571428656578064 - Test Acc: 0.8000000715255737\n",
      "Epoch 1400/1500 - Loss: 1.3875291347503662 - Train Acc: 0.22857142984867096 - Test Acc: 0.20000001788139343\n",
      "Epoch 1500/1500 - Loss: 1.3453069925308228 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.25714287, 0.25714287, 0.25714287, ..., 0.2857143 , 0.2857143 ,\n",
       "        0.2857143 ]),\n",
       " array([nan, nan, nan, ..., nan, nan, nan]),\n",
       " array([0.40000004, 0.40000004, 0.40000004, ..., 0.20000002, 0.20000002,\n",
       "        0.20000002]),\n",
       " array([4.64778760e+03, 5.01208057e+03, 3.23080396e+03, ...,\n",
       "        1.34531176e+00, 1.34530771e+00, 1.34530699e+00]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GNN Ignore\n",
    "gcn_ignore = arch.GCNCoefs(S_gcn, in_dim, hid_dim, out_dim, n_layers, L).to(device)\n",
    "model_gnn_ignore = model.Model(gcn_ignore, n_epochs*n_iters, lr, wd, eval_freq)\n",
    "\n",
    "model_gnn_ignore.test_clas(S_gcn, X, Y, gamma, dataset.train_mask, [], dataset.test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500 - Loss: 3887.753662109375 - Train Acc: 0.22857142984867096 - Test Acc: 0.20000001788139343\n",
      "Epoch 100/1500 - Loss: 107.62351989746094 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n",
      "Epoch 200/1500 - Loss: 20.154563903808594 - Train Acc: 0.2571428716182709 - Test Acc: 0.40000003576278687\n",
      "Epoch 300/1500 - Loss: 107.38243865966797 - Train Acc: 0.2571428716182709 - Test Acc: 0.40000003576278687\n",
      "Epoch 400/1500 - Loss: 1.723096489906311 - Train Acc: 0.2571428716182709 - Test Acc: 0.40000003576278687\n",
      "Epoch 500/1500 - Loss: 1.2880223989486694 - Train Acc: 0.37142857909202576 - Test Acc: 0.2666666805744171\n",
      "Epoch 600/1500 - Loss: 1.7701258659362793 - Train Acc: 0.2571428716182709 - Test Acc: 0.40000003576278687\n",
      "Epoch 700/1500 - Loss: 1.354291558265686 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n",
      "Epoch 800/1500 - Loss: 1.3483444452285767 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n",
      "Epoch 900/1500 - Loss: 1.3493850231170654 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n",
      "Epoch 1000/1500 - Loss: 1.3490968942642212 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n",
      "Epoch 1100/1500 - Loss: 1.3488966226577759 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n",
      "Epoch 1200/1500 - Loss: 1.3486769199371338 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n",
      "Epoch 1300/1500 - Loss: 1.3484249114990234 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n",
      "Epoch 1400/1500 - Loss: 1.3481379747390747 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n",
      "Epoch 1500/1500 - Loss: 1.3478052616119385 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.22857143, 0.2857143 , 0.25714287, ..., 0.2857143 , 0.2857143 ,\n",
       "        0.2857143 ]),\n",
       " array([nan, nan, nan, ..., nan, nan, nan]),\n",
       " array([0.20000002, 0.20000002, 0.40000004, ..., 0.20000002, 0.20000002,\n",
       "        0.20000002]),\n",
       " array([3.88775366e+03, 1.23569141e+03, 4.45070068e+03, ...,\n",
       "        1.34781432e+00, 1.34780943e+00, 1.34780526e+00]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_ten = torch.Tensor(dataset.S).to(device)\n",
    "\n",
    "gcn_unpert = arch.GCNCoefs(S_ten, in_dim, hid_dim, out_dim, n_layers, L).to(device)\n",
    "model_gnn_unpert = model.Model(gcn_unpert, n_epochs*n_iters, lr, wd, eval_freq)\n",
    "\n",
    "model_gnn_unpert.test_clas(S_ten, X, Y, gamma, dataset.train_mask, [], dataset.test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ Iteration 0 ***********Epoch 1/50 - Loss: 5020.2421875 - Train Acc: 0.2571428716182709 - Test Acc: 0.40000003576278687\n",
      "Stats: err_h=2.827316064735605 - err_H=25672.028248497532 - err_S=59.99992161775494 - losses[i,-1]=282.5556335449219\n",
      "************ Iteration 1 ***********Epoch 1/50 - Loss: 264.3282775878906 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n",
      "Stats: err_h=1.416375072963753 - err_H=25718.087890905488 - err_S=59.999966967304616 - losses[i,-1]=69.42282104492188\n",
      "************ Iteration 2 ***********Epoch 1/50 - Loss: 68.16173553466797 - Train Acc: 0.22857142984867096 - Test Acc: 0.20000001788139343\n",
      "Stats: err_h=1.0168451221824368 - err_H=150639.51352008755 - err_S=59.99989097684113 - losses[i,-1]=7.177703380584717\n",
      "************ Iteration 3 ***********Epoch 1/50 - Loss: 22.5211124420166 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n",
      "Stats: err_h=1.0082480725181182 - err_H=144500.70361822378 - err_S=59.9998987379738 - losses[i,-1]=1.4124494791030884\n",
      "************ Iteration 4 ***********Epoch 1/50 - Loss: 1.3868000507354736 - Train Acc: 0.2571428716182709 - Test Acc: 0.40000003576278687\n",
      "Stats: err_h=0.9983097166772763 - err_H=139708.3533943462 - err_S=60.0 - losses[i,-1]=1.220179796218872\n",
      "************ Iteration 5 ***********Epoch 1/50 - Loss: 1.212127923965454 - Train Acc: 0.4000000059604645 - Test Acc: 0.5333333611488342\n",
      "Stats: err_h=1.0346364899106235 - err_H=140727.1720682629 - err_S=60.0 - losses[i,-1]=1.6766878366470337\n",
      "************ Iteration 6 ***********Epoch 1/50 - Loss: 2.405911684036255 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n",
      "Stats: err_h=1.0279097457833486 - err_H=142230.57511977968 - err_S=60.0 - losses[i,-1]=1.449946641921997\n",
      "************ Iteration 7 ***********Epoch 1/50 - Loss: 1.5335520505905151 - Train Acc: 0.20000000298023224 - Test Acc: 0.20000001788139343\n",
      "Stats: err_h=1.0331813450455571 - err_H=142114.2803499117 - err_S=60.0 - losses[i,-1]=1.3103954792022705\n",
      "************ Iteration 8 ***********Epoch 1/50 - Loss: 1.279969334602356 - Train Acc: 0.34285715222358704 - Test Acc: 0.46666669845581055\n",
      "Stats: err_h=1.0240126408472023 - err_H=138824.56320291068 - err_S=60.0 - losses[i,-1]=1.36501944065094\n",
      "************ Iteration 9 ***********Epoch 1/50 - Loss: 1.3921314477920532 - Train Acc: 0.2571428716182709 - Test Acc: 0.40000003576278687\n",
      "Stats: err_h=1.023889442119474 - err_H=144111.78067579094 - err_S=60.0 - losses[i,-1]=8.00412368774414\n",
      "************ Iteration 10 ***********Epoch 1/50 - Loss: 5.893845081329346 - Train Acc: 0.22857142984867096 - Test Acc: 0.20000001788139343\n",
      "Stats: err_h=1.0250451378808347 - err_H=141959.30290634604 - err_S=60.0 - losses[i,-1]=1.3259553909301758\n",
      "************ Iteration 11 ***********Epoch 1/50 - Loss: 1.4326821565628052 - Train Acc: 0.34285715222358704 - Test Acc: 0.3333333432674408\n",
      "Stats: err_h=1.027042557894807 - err_H=142023.5931782852 - err_S=60.0 - losses[i,-1]=1.3481277227401733\n",
      "************ Iteration 12 ***********Epoch 1/50 - Loss: 1.3443952798843384 - Train Acc: 0.2571428716182709 - Test Acc: 0.40000003576278687\n",
      "Stats: err_h=1.0180669908558646 - err_H=139357.95796505525 - err_S=60.0 - losses[i,-1]=2.1948111057281494\n",
      "************ Iteration 13 ***********Epoch 1/50 - Loss: 2.068178653717041 - Train Acc: 0.22857142984867096 - Test Acc: 0.20000001788139343\n",
      "Stats: err_h=1.0296628748397696 - err_H=151802.34528356369 - err_S=60.0 - losses[i,-1]=6.587463855743408\n",
      "************ Iteration 14 ***********Epoch 1/50 - Loss: 4.1858720779418945 - Train Acc: 0.2571428716182709 - Test Acc: 0.40000003576278687\n",
      "Stats: err_h=1.0186188527251308 - err_H=139294.88444872852 - err_S=60.0 - losses[i,-1]=1.4393303394317627\n",
      "************ Iteration 15 ***********Epoch 1/50 - Loss: 1.435734510421753 - Train Acc: 0.22857142984867096 - Test Acc: 0.20000001788139343\n",
      "Stats: err_h=1.0252475373232222 - err_H=141912.85778806114 - err_S=60.0 - losses[i,-1]=1.5999304056167603\n",
      "************ Iteration 16 ***********Epoch 1/50 - Loss: 1.2950913906097412 - Train Acc: 0.3142857253551483 - Test Acc: 0.46666669845581055\n",
      "Stats: err_h=1.034736825582462 - err_H=147107.30596793082 - err_S=59.9999011359833 - losses[i,-1]=1.4348430633544922\n",
      "************ Iteration 17 ***********Epoch 1/50 - Loss: 1.4910720586776733 - Train Acc: 0.22857142984867096 - Test Acc: 0.20000001788139343\n",
      "Stats: err_h=1.0317636579462095 - err_H=139101.37718077257 - err_S=60.0 - losses[i,-1]=2.4507291316986084\n",
      "************ Iteration 18 ***********Epoch 1/50 - Loss: 2.9283409118652344 - Train Acc: 0.22857142984867096 - Test Acc: 0.20000001788139343\n",
      "Stats: err_h=1.0501351232721077 - err_H=141075.7270691067 - err_S=60.0 - losses[i,-1]=1.1398042440414429\n",
      "************ Iteration 19 ***********Epoch 1/50 - Loss: 1.161418080329895 - Train Acc: 0.4571428596973419 - Test Acc: 0.46666669845581055\n",
      "Stats: err_h=1.042173104353944 - err_H=143327.8450275278 - err_S=60.0 - losses[i,-1]=1.5878962278366089\n",
      "************ Iteration 20 ***********Epoch 1/50 - Loss: 1.598070740699768 - Train Acc: 0.22857142984867096 - Test Acc: 0.20000001788139343\n",
      "Stats: err_h=1.0370953490060661 - err_H=139039.29777689045 - err_S=60.0 - losses[i,-1]=2.199178457260132\n",
      "************ Iteration 21 ***********Epoch 1/50 - Loss: 2.379835844039917 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n",
      "Stats: err_h=1.0412792056571782 - err_H=142776.4351294842 - err_S=60.0 - losses[i,-1]=1.3551241159439087\n",
      "************ Iteration 22 ***********Epoch 1/50 - Loss: 1.3532358407974243 - Train Acc: 0.2571428716182709 - Test Acc: 0.40000003576278687\n",
      "Stats: err_h=1.0381978734056108 - err_H=139282.56875308682 - err_S=60.0 - losses[i,-1]=2.7384777069091797\n",
      "************ Iteration 23 ***********Epoch 1/50 - Loss: 2.1734678745269775 - Train Acc: 0.22857142984867096 - Test Acc: 0.20000001788139343\n",
      "Stats: err_h=1.0305773711137167 - err_H=142236.94134729216 - err_S=60.0 - losses[i,-1]=1.522766351699829\n",
      "************ Iteration 24 ***********Epoch 1/50 - Loss: 1.3565747737884521 - Train Acc: 0.37142857909202576 - Test Acc: 0.46666669845581055\n",
      "Stats: err_h=1.0320474489364924 - err_H=140276.2508290484 - err_S=60.0 - losses[i,-1]=1.362339973449707\n",
      "************ Iteration 25 ***********Epoch 1/50 - Loss: 1.3545985221862793 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n",
      "Stats: err_h=1.0509861908700586 - err_H=141979.18530796326 - err_S=60.0 - losses[i,-1]=1.2604504823684692\n",
      "************ Iteration 26 ***********Epoch 1/50 - Loss: 1.2148633003234863 - Train Acc: 0.4285714328289032 - Test Acc: 0.6000000238418579\n",
      "Stats: err_h=1.05047466933462 - err_H=139969.59639518702 - err_S=60.0 - losses[i,-1]=1.3615666627883911\n",
      "************ Iteration 27 ***********Epoch 1/50 - Loss: 1.3607984781265259 - Train Acc: 0.3142857253551483 - Test Acc: 0.40000003576278687\n",
      "Stats: err_h=1.055143568887746 - err_H=141856.97449879683 - err_S=60.0 - losses[i,-1]=1.225251317024231\n",
      "************ Iteration 28 ***********Epoch 1/50 - Loss: 1.227936029434204 - Train Acc: 0.37142857909202576 - Test Acc: 0.5333333611488342\n",
      "Stats: err_h=1.0462531083410924 - err_H=138634.0133325573 - err_S=60.0 - losses[i,-1]=1.388226866722107\n",
      "************ Iteration 29 ***********Epoch 1/50 - Loss: 1.3988971710205078 - Train Acc: 0.2857142984867096 - Test Acc: 0.20000001788139343\n",
      "Stats: err_h=1.0273275547180774 - err_H=139225.25476071413 - err_S=60.0 - losses[i,-1]=1.2986658811569214\n"
     ]
    }
   ],
   "source": [
    "S_id = dataset.Sn.copy()\n",
    "\n",
    "gcn_model = arch.GCNCoefs(S_gcn, in_dim, hid_dim, out_dim, n_layers, L).to(device)\n",
    "model_gcn_robust = model.Model(gcn_model, n_epochs, lr, wd, eval_freq)\n",
    "\n",
    "acc_train = np.zeros((n_iters, n_epochs))\n",
    "acc_test = np.zeros((n_iters, n_epochs))\n",
    "losses = np.zeros((n_iters, n_epochs))\n",
    "\n",
    "for i in range(n_iters):\n",
    "    #print(\"**************************************\")\n",
    "    print(f\"************ Iteration {i} ***********\", end=\"\")\n",
    "    #print(\"**************************************\")\n",
    "\n",
    "    S_gcn = torch.Tensor(S_id).to(device)\n",
    "\n",
    "    gcn_model.update_Spow(S_gcn)\n",
    "    \n",
    "    # Filter estimation\n",
    "    #gcn_model = GCN(S_gcn, in_dim, hid_dim, out_dim, n_layers, K).to(device)\n",
    "    #gcn_model.h.data = h_id\n",
    "    acc_train[i,:], _, acc_test[i,:], losses[i,:] = model_gcn_robust.test_clas(S_ten, X, Y, gamma, dataset.train_mask, [], dataset.test_mask)\n",
    "\n",
    "    h_id = gcn_model.h.data\n",
    "    H_id = torch.sum(h_id[:,None,None]*gcn_model.Spow, 0).cpu().numpy()\n",
    "\n",
    "    #print(\"Graph identification\")\n",
    "    # Graph estimation\n",
    "    S_id = graph_id(dataset.Sn, H_id, dataset.Cy, lambd, gamma, delta)\n",
    "\n",
    "    err_h = ((dataset.h - h_id.cpu().numpy())**2).sum()\n",
    "    err_H = ((dataset.H - H_id)**2).sum()\n",
    "    err_S = ((dataset.S - S_id)**2).sum()\n",
    "    print(f\"Stats: {err_h=} - {err_H=} - {err_S=} - {losses[i,-1]=}\")\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
